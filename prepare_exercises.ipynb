{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "012e8001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import mechanize\n",
    "#import http.cookiejar as cookiejar\n",
    "import re\n",
    "import requests\n",
    "import html\n",
    "import unicodedata\n",
    "import json\n",
    "import acquire\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd05175e",
   "metadata": {},
   "source": [
    "### Exercises \n",
    "\n",
    "- The end result of this exercise should be a file named prepare.py that defines the requested functions.\n",
    "\n",
    "- In this exercise we will be defining some functions to prepare textual data. These functions should apply equally well to both the codeup blog articles and the news articles that were previously acquired.\n",
    "\n",
    "1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "        Lowercase everything\n",
    "        Normalize unicode characters\n",
    "        Replace anything that is not a letter, number, whitespace or a single quote.\n",
    "\n",
    "2. Define a function named tokenize. It should take in a string and tokenize all the words in the string.\n",
    "\n",
    "3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words.\n",
    "\n",
    "4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word.\n",
    "\n",
    "5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "        This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove.\n",
    "\n",
    "6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df.\n",
    "\n",
    "7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df.\n",
    "\n",
    "8. For each dataframe, produce the following columns:\n",
    "\n",
    "        title to hold the title\n",
    "        original to hold the original article/post content\n",
    "        clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "        stemmed to hold the stemmed version of the cleaned data.\n",
    "        lemmatized to hold the lemmatized version of the cleaned data.\n",
    "\n",
    "9. Ask yourself:\n",
    "\n",
    "        If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "        If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "        If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf168916",
   "metadata": {},
   "source": [
    "### 1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "     Lowercase everything\n",
    "     Normalize unicode characters\n",
    "     Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfc914fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    string = string.lower()\n",
    "    string = unicodedata.normalize('NFKD', string)\\\n",
    "        .encode('ascii', 'ignore')\\\n",
    "        .decode('utf-8', 'ignore')\n",
    "    string = re.sub(r\"[^a-z0-9'\\s]\", '', string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bb9059",
   "metadata": {},
   "source": [
    "### 2. Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c1f9878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    return(tokenizer.tokenize(string, return_str=True)[0:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd10cf0",
   "metadata": {},
   "source": [
    "### 3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7769eed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a string with words stemmed.\n",
    "    '''\n",
    "    # create our stemming object\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    # use a list comprehension => stem each word for each word inside of the entire document,\n",
    "    # split by the default, which are single spaces\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    # glue it back together with spaces, as it was before\n",
    "    string = ' '.join(stems)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f14a1d8",
   "metadata": {},
   "source": [
    "### 4.Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "295b880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    for word in text.split():\n",
    "        return('stem:', ps.stem(word), '-- lemma:', wnl.lemmatize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d053329f",
   "metadata": {},
   "source": [
    "### 5.Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "    This function should define two optional parameters, extra_words and exclude_words. \n",
    "    These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e70403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stopword_list = stopwords.words('english')\n",
    "    stopword_list.remove('no')\n",
    "    stopword_list.remove('not')\n",
    "    stopword_list[:10]\n",
    "    words = text.split()\n",
    "    filtered_text = [w for w in words if w not in stopword_list]\n",
    "    return filtered_text\n",
    "    text_without_stopwords = ' '.join(filtered_text)\n",
    "    return text_without_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d167b289",
   "metadata": {},
   "source": [
    "### 6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f90788ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = acquire.get_news_articles_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0320604",
   "metadata": {},
   "source": [
    "### 7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d74e230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "codeup_df = acquire.get_blog_articles_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3798eb",
   "metadata": {},
   "source": [
    "### 8. For each dataframe, produce the following columns:\n",
    "\n",
    "     title to hold the title\n",
    "     original to hold the original article/post content\n",
    "     clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "     stemmed to hold the stemmed version of the cleaned data.\n",
    "     lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63cd7c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rebel Sena MP is party's leader in Lok Sabha, ...</td>\n",
       "      <td>Maharashtra Chief Minister Eknath Shinde on Tu...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Situation is exceptional but comparing it with...</td>\n",
       "      <td>The government hosted an all-party meeting on ...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Huge sinkhole opens up in New York City, swall...</td>\n",
       "      <td>A video has gone viral showing a huge sinkhole...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Farmer files complaint against Lord Indra over...</td>\n",
       "      <td>A UP farmer submitted a written complaint to t...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I retired from ODIs due to horrendous schedule...</td>\n",
       "      <td>Ex-England captain Kevin Pietersen took to Twi...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Rebel Sena MP is party's leader in Lok Sabha, ...   \n",
       "1  Situation is exceptional but comparing it with...   \n",
       "2  Huge sinkhole opens up in New York City, swall...   \n",
       "3  Farmer files complaint against Lord Indra over...   \n",
       "4  I retired from ODIs due to horrendous schedule...   \n",
       "\n",
       "                                             content  category  \n",
       "0  Maharashtra Chief Minister Eknath Shinde on Tu...  national  \n",
       "1  The government hosted an all-party meeting on ...  national  \n",
       "2  A video has gone viral showing a huge sinkhole...  national  \n",
       "3  A UP farmer submitted a written complaint to t...  national  \n",
       "4  Ex-England captain Kevin Pietersen took to Twi...  national  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "71bb9c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['original'] = news_df.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c07ef000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rebel Sena MP is party's leader in Lok Sabha, ...</td>\n",
       "      <td>Maharashtra Chief Minister Eknath Shinde on Tu...</td>\n",
       "      <td>national</td>\n",
       "      <td>Maharashtra Chief Minister Eknath Shinde on Tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Situation is exceptional but comparing it with...</td>\n",
       "      <td>The government hosted an all-party meeting on ...</td>\n",
       "      <td>national</td>\n",
       "      <td>The government hosted an all-party meeting on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Huge sinkhole opens up in New York City, swall...</td>\n",
       "      <td>A video has gone viral showing a huge sinkhole...</td>\n",
       "      <td>national</td>\n",
       "      <td>A video has gone viral showing a huge sinkhole...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Farmer files complaint against Lord Indra over...</td>\n",
       "      <td>A UP farmer submitted a written complaint to t...</td>\n",
       "      <td>national</td>\n",
       "      <td>A UP farmer submitted a written complaint to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I retired from ODIs due to horrendous schedule...</td>\n",
       "      <td>Ex-England captain Kevin Pietersen took to Twi...</td>\n",
       "      <td>national</td>\n",
       "      <td>Ex-England captain Kevin Pietersen took to Twi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Rebel Sena MP is party's leader in Lok Sabha, ...   \n",
       "1  Situation is exceptional but comparing it with...   \n",
       "2  Huge sinkhole opens up in New York City, swall...   \n",
       "3  Farmer files complaint against Lord Indra over...   \n",
       "4  I retired from ODIs due to horrendous schedule...   \n",
       "\n",
       "                                             content  category  \\\n",
       "0  Maharashtra Chief Minister Eknath Shinde on Tu...  national   \n",
       "1  The government hosted an all-party meeting on ...  national   \n",
       "2  A video has gone viral showing a huge sinkhole...  national   \n",
       "3  A UP farmer submitted a written complaint to t...  national   \n",
       "4  Ex-England captain Kevin Pietersen took to Twi...  national   \n",
       "\n",
       "                                            original  \n",
       "0  Maharashtra Chief Minister Eknath Shinde on Tu...  \n",
       "1  The government hosted an all-party meeting on ...  \n",
       "2  A video has gone viral showing a huge sinkhole...  \n",
       "3  A UP farmer submitted a written complaint to t...  \n",
       "4  Ex-England captain Kevin Pietersen took to Twi...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d86ecbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['clean'] = news_df.content.apply(basic_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "32a08e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      maharashtra chief minister eknath shinde on tu...\n",
       "1      the government hosted an allparty meeting on s...\n",
       "2      a video has gone viral showing a huge sinkhole...\n",
       "3      a up farmer submitted a written complaint to t...\n",
       "4      exengland captain kevin pietersen took to twit...\n",
       "                             ...                        \n",
       "295    authorities in karnataka's dakshina kannada di...\n",
       "296    at least 22 people were killed and 33 people w...\n",
       "297    the management of the vishnu temple in canada'...\n",
       "298    india is on course to achieve projected 885 gr...\n",
       "299    hindustan unilever limited hul on tuesday repo...\n",
       "Name: clean, Length: 300, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c44e2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      maharashtra chief minister eknath shinde on tu...\n",
       "1      the government hosted an allparty meeting on s...\n",
       "2      a video has gone viral showing a huge sinkhole...\n",
       "3      a up farmer submitted a written complaint to t...\n",
       "4      exengland captain kevin pietersen took to twit...\n",
       "                             ...                        \n",
       "295    authorities in karnataka ' s dakshina kannada ...\n",
       "296    at least 22 people were killed and 33 people w...\n",
       "297    the management of the vishnu temple in canada ...\n",
       "298    india is on course to achieve projected 885 gr...\n",
       "299    hindustan unilever limited hul on tuesday repo...\n",
       "Name: clean, Length: 300, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['clean'] = news_df.clean.apply(tokenize)\n",
    "news_df['clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9e240c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [maharashtra, chief, minister, eknath, shinde,...\n",
       "1      [government, hosted, allparty, meeting, sri, l...\n",
       "2      [video, gone, viral, showing, huge, sinkhole, ...\n",
       "3      [farmer, submitted, written, complaint, local,...\n",
       "4      [exengland, captain, kevin, pietersen, took, t...\n",
       "                             ...                        \n",
       "295    [authorities, karnataka, ', dakshina, kannada,...\n",
       "296    [least, 22, people, killed, 33, people, injure...\n",
       "297    [management, vishnu, temple, canada, ', toront...\n",
       "298    [india, course, achieve, projected, 885, growt...\n",
       "299    [hindustan, unilever, limited, hul, tuesday, r...\n",
       "Name: clean, Length: 300, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['clean'] = news_df.clean.apply(remove_stopwords)\n",
    "news_df['clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "23ac1f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      maharashtra chief minist eknath shind on tuesd...\n",
       "1      the govern host an all-parti meet on sri lanka...\n",
       "2      a video ha gone viral show a huge sinkhol open...\n",
       "3      a up farmer submit a written complaint to the ...\n",
       "4      ex-england captain kevin pietersen took to twi...\n",
       "                             ...                        \n",
       "295    author in karnataka' dakshina kannada district...\n",
       "296    at least 22 peopl were kill and 33 peopl were ...\n",
       "297    the manag of the vishnu templ in canada' toron...\n",
       "298    india is on cours to achiev project 8-8.5% gro...\n",
       "299    hindustan unilev limit (hul) on tuesday report...\n",
       "Name: stemmed, Length: 300, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['stemmed'] = news_df['content'].apply(stem)\n",
    "news_df['stemmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e36daea6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s4/hmz6ljm533vgpm_bhv59yw0m0000gn/T/ipykernel_82134/2444423497.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnews_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lemmatized'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnews_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 \u001b[0;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m                 \u001b[0;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/var/folders/s4/hmz6ljm533vgpm_bhv59yw0m0000gn/T/ipykernel_82134/2674889565.py\u001b[0m in \u001b[0;36mlemmatization\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlemmatization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mwnl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stem:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-- lemma:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwnl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "news_df['lemmatized'] = news_df.clean.apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7d4f8c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s4/hmz6ljm533vgpm_bhv59yw0m0000gn/T/ipykernel_82134/1715613638.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#clean = basic_clean(string)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclean\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mclean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_stopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdf_news\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/s4/hmz6ljm533vgpm_bhv59yw0m0000gn/T/ipykernel_82134/1389441537.py\u001b[0m in \u001b[0;36mremove_stopwords\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstopword_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'not'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstopword_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mfiltered_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopword_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfiltered_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'split'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fad9cb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Maharashtra Chief Minister Eknath Shinde on Tuesday said Lok Sabha Speaker Om Birla has recognised rebel Shiv Sena MP Rahul Shewale as the party \\' s floor leader in the Lower House of Parliament. \" Shiv Sena MPs too have supported us in our stand to uphold ideals of Balasaheb Thackeray , \" Shinde added , while speaking to mediapersons in Delhi .'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9054116b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maharashtra',\n",
       " 'Chief',\n",
       " 'Minister',\n",
       " 'Eknath',\n",
       " 'Shinde',\n",
       " 'Tuesday',\n",
       " 'said',\n",
       " 'Lok',\n",
       " 'Sabha',\n",
       " 'Speaker',\n",
       " 'Om',\n",
       " 'Birla',\n",
       " 'recognised',\n",
       " 'rebel',\n",
       " 'Shiv',\n",
       " 'Sena',\n",
       " 'MP',\n",
       " 'Rahul',\n",
       " 'Shewale',\n",
       " \"party's\",\n",
       " 'floor',\n",
       " 'leader',\n",
       " 'Lower',\n",
       " 'House',\n",
       " 'Parliament.',\n",
       " '\"Shiv',\n",
       " 'Sena',\n",
       " 'MPs',\n",
       " 'supported',\n",
       " 'us',\n",
       " 'stand',\n",
       " 'uphold',\n",
       " 'ideals',\n",
       " 'Balasaheb',\n",
       " 'Thackeray,\"',\n",
       " 'Shinde',\n",
       " 'added,',\n",
       " 'speaking',\n",
       " 'mediapersons',\n",
       " 'Delhi.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fed816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
